#!python

"""
    Performance testing to find an acceptable K value + Attempting to create adaptive-K strategy
"""

import numpy as np 
import pandas as pd
import numcodecs
import zarr
from tqdm import tqdm
import allel
import glob
import csv
import sys
sys.path.append('src/')
from scipy.spatial.distance import squareform
from gen_ld_mat import *
from utils import *
from perf import *

# ------- Data Directories ------ # 
DATA_DIR  = '/project2/jnovembre/data/external_public/geo_LD/'
VCF_1KG_DIR = '/project2/jnovembre/data/external_public/1kg_phase3/haps/'

#------ Rules ------ # 

rule filt_biallelic_AC_1kg:
    """
       Filter to biallelic SNPs in the 1000 Genomes Dataset (with a particular
       allele count filter)
    """
    input:
      vcf =  VCF_1KG_DIR + 'ALL.chr{CHROM}.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz'
    output:
      vcf = DATA_DIR  + 'ALL.chr{CHROM}.phase3_shapeit2_mvncall_integrated.20130502.biallelic_snps.ac{AC,\d+}.genotypes.vcf.gz',
      vcf_idx = DATA_DIR  + 'ALL.chr{CHROM}.phase3_shapeit2_mvncall_integrated.20130502.biallelic_snps.ac{AC,\d+}.genotypes.vcf.gz.tbi' 
    shell:
      """
      bcftools view -v snps -m2 -M2 -c {wildcards.AC}:minor {input.vcf} | bgzip -@4 > {output.vcf}    
      tabix -f {output.vcf}
      """
    

         
rule regional_full_LD_mat:
    """
       Generate full LD matrix for the chosen segment of a particular chromosome for individuals from a certain population 
    """
    input:
      vcf = rules.filt_biallelic_AC_1kg.output.vcf,
      popfile = VCF_1KG_DIR + 'integrated_call_samples_v3.20130502.ALL.panel' 
    output:
      ld_mat = 'data/ld_mats_perf/chr{CHROM}_ac{AC,\d+}_full_LD_pos{POS1,\d+}_{POS2,\d+}_pop{POP}.npz'
    run:
       # Reading in vcf 
       callset = allel.read_vcf(input.vcf, region=(str(wildcards.CHROM))+':'+str(wildcards.POS1)+'-'+str(wildcards.POS2), fields=['calldata/GT','samples','variants/POS'])
       # Creating genotype array
       gt = allel.GenotypeArray(callset['calldata/GT'])
       # Filtering out individuals of specific population
       panel = pd.read_csv(input.popfile, sep='\t', usecols=['sample', 'pop', 'super_pop'])
       pop_check = (panel['pop']==wildcards.POP)
       pop_indices = panel[pop_check].index.values
       pop_gt = gt.take(pop_indices,axis=1)
       # Creating summed genotype matrix (2D)
       a = pop_gt.to_n_alt()
       snp_indices = []
       # Filtering out non-segregating sites in the specified population
       idx1 = ~np.all(a==0, axis=1)
       idx2 = ~np.all(a==1, axis=1)
       idx3 = ~np.all(a==2, axis=1)
       # Creating arrays of indices and positions of segregating SNPs
       for i in range(idx1.shape[0]):
        if idx1[i]==True and idx2[i]==True and idx3[i]==True:
            snp_indices.append(i)
       snp_indices = np.array(snp_indices)
       pos = callset['variants/POS'][idx1 & idx2 & idx3]
       a = a[idx1 & idx2 & idx3]
       # Calculating allele frequency
       alt_ac = np.nansum(a, axis=1)
       alt_af = alt_ac / (2*a.shape[1])
       # Creating full LD matrix
       ld_mat = np.corrcoef(a)**2
       ld_mat = ld_mat.astype('float16')
       variables = np.array([(str(wildcards.POP)),(str(wildcards.POS1)+"-"+str(wildcards.POS2))])
       np.savez_compressed(output.ld_mat,ld_mat=ld_mat,snp_indices=snp_indices,pos=pos,alt_af=alt_af,variables=variables)

rule gen_full_LD_mat:
  input:
    expand('data/ld_mats_perf/chr{CHROM}_ac{AC}_full_LD_pos{POS1}_{POS2}_pop{POP}.npz', AC=5, POP=['CEU','YRI','CHB','FIN','MXL','ASW'], CHROM=22, POS1=41000000, POS2=44000000),        
        
      
# ----------------- K x P Analysis --------------------- # 
rule kxp_select_positions:
    """
       Generate k x p matrix for a chosen segment of a particular chromosome for individuals from a certain population, 
       Filtering out non-segregating sites in that particular population
    """
    input:
      vcf = rules.filt_biallelic_AC_1kg.output.vcf,
      popfile = VCF_1KG_DIR + 'integrated_call_samples_v3.20130502.ALL.panel' 
    output:
      ld_mat = 'data/performance_tests/chr{CHROM}_ac{AC,\d+}_K{K,\d+}_pos{POS1,\d+}_{POS2,\d+}_pop{POP}.npz'
    run:
       # Reading in vcf 
       callset = allel.read_vcf(input.vcf, region=(str(wildcards.CHROM))+':'+str(wildcards.POS1)+'-'+str(wildcards.POS2), fields=['calldata/GT','samples','variants/POS'])
       # Creating genotype array
       gt = allel.GenotypeArray(callset['calldata/GT'])
       # Filtering out individuals of specific population
       panel = pd.read_csv(input.popfile, sep='\t', usecols=['sample', 'pop', 'super_pop'])
       pop_check = (panel['pop']==wildcards.POP)
       pop_indices = panel[pop_check].index.values
       pop_vec = panel['pop'].values
       pop_vec = pop_vec[pop_check]
       pop_gt = gt.take(pop_indices,axis=1)
       # Creating summed genotype matrix (2D)
       a = pop_gt.to_n_alt()
       snp_indices = []
       # Filtering out non-segregating sites in the specified population
        # (NOTE : this can be done with a check on the allele frequency)
       idx1 = ~np.all(a==0, axis=1)
       idx2 = ~np.all(a==1, axis=1)
       idx3 = ~np.all(a==2, axis=1)
       for i in range(idx1.shape[0]):
        if idx1[i]==True and idx2[i]==True and idx3[i]==True:
            snp_indices.append(i)
       # Creating arrays of indices and positions of segregating SNPs 
       snp_indices = np.array(snp_indices)
       pos = callset['variants/POS'][idx1 & idx2 & idx3]
       a = a[idx1 & idx2 & idx3]
       # Creating k x p matrix 
       ld_mat, alt_af = est_kxp_mat(a, pop_vec, wildcards.POP, int(wildcards.K))
       np.savez_compressed(output.ld_mat,ld_mat=ld_mat,snp_indices=snp_indices, pos=pos,alt_af=alt_af)
    
rule unfiltered_kxp_positions:
    """
       Generate k x p matrix for a chosen segment of a particular chromosome for individuals from a certain population,
       WITHOUT filtering out non-segregating sites in the population
    """
    input:
      vcf = rules.filt_biallelic_AC_1kg.output.vcf,
      popfile = VCF_1KG_DIR + 'integrated_call_samples_v3.20130502.ALL.panel' 
    output:
      ld_mat = 'data/performance_tests/chr{CHROM}_ac{AC,\d+}_K{K,\d+}_pos{POS1,\d+}_{POS2,\d+}_unfiltered_pop{POP}.npz'
    run:
       # Reading in vcf 
       callset = allel.read_vcf(input.vcf, region=(str(wildcards.CHROM))+':'+str(wildcards.POS1)+'-'+str(wildcards.POS2), fields=['calldata/GT','samples','variants/POS'])
       # Creating genotype array
       gt = allel.GenotypeArray(callset['calldata/GT'])
       # Filtering out individuals of specific population
       panel = pd.read_csv(input.popfile, sep='\t', usecols=['sample', 'pop', 'super_pop'])
       pop_check = (panel['pop']==wildcards.POP)
       pop_indices = panel[pop_check].index.values
       pop_vec = panel['pop'].values
       pop_vec = pop_vec[pop_check]
       pop_gt = gt.take(pop_indices,axis=1)
       # Creating summed genotype matrix (2D)
       a = pop_gt.to_n_alt()   
       # Creating arrays of indices and positions of segregating SNPs 
       pos = callset['variants/POS']
       # Creating k x p matrix 
       ld_mat, alt_af = est_kxp_mat(a, pop_vec, wildcards.POP, int(wildcards.K))
       np.savez_compressed(output.ld_mat,ld_mat=ld_mat, pos=pos,alt_af=alt_af)
      
rule gen_pop_kxp_matrix:
  input:
    expand('data/performance_tests/chr{CHROM}_ac{AC}_K{K}_pos{POS1}_{POS2}_pop{POP}.npz', AC=5, POP=['CEU'], K=[100,200,326,500,1000], CHROM=22, POS1=20000000, POS2=25000000),

        
rule adaptive_k_single_pop_chrom:
    """
        Generate list containing r2 arrays for each SNP on a chromosome for a population
    """
    input:
      vcf = rules.filt_biallelic_AC_1kg.output.vcf,
      popfile = VCF_1KG_DIR + 'integrated_call_samples_v3.20130502.ALL.panel'
    output:
      adaptive_ld_mat = 'data/performance_tests/adaptive_chr{CHROM}_eps{EPS,\d+}_N{N,\d+}_blen{BLEN,\d+}_ac{AC,\d+}_pos{POS1,\d+}_{POS2,\d+}_pop{POP}.npz'    
    run:
      # Reading in vcf
      callset = allel.read_vcf(input.vcf, region=(str(wildcards.CHROM))+':'+str(wildcards.POS1)+'-'+str(wildcards.POS2), 
                               fields=['variants/CHROM', 'calldata/GT','samples','variants/POS'])
      chroms = callset['variants/CHROM']
      positions = callset['variants/POS']
      # Generating genotype array
      gt = allel.GenotypeArray(callset['calldata/GT'])
      # Filtering out particular population
      panel = pd.read_csv(input.popfile, sep='\t', usecols=['sample', 'pop', 'super_pop'])
      pop_check = (panel['pop']==wildcards.POP)
      pop_indices = panel[pop_check].index.values
      pop_gt = gt.take(pop_indices, axis=1)
      # Creating summed genotype matrix
      gt_mat = pop_gt.to_n_alt()
      _, nsamp = gt_mat.shape
      # Calculate alt AF
      alt_af = np.sum(gt_mat, axis=1)/(2*nsamp)
      
      # Filter this to only the sites that are polymorphic
      idx_polymorphic = ((alt_af > 0) & (alt_af < 1))
      alt_af_filt = alt_af[idx_polymorphic]
      gt_mat_filt = gt_mat[idx_polymorphic,:]
      nsnps_filt, nsamp_filt = gt_mat_filt.shape
      
      # Empty list for arrays
      full_r2_list = []
      # Appending each array to list and saving
      for i in tqdm(range(nsnps_filt)):
        snp_r2_adaptive = adaptive_ld_mat_snp(gt_mat_filt, i,int(wildcards.EPS)/10000,int(wildcards.N),int(wildcards.BLEN))
        full_r2_list.append(snp_r2_adaptive)
      # Check the dimension of these arrays to make sure they are all 1-d
      dims = np.array([x.ndim for x in full_r2_list])
      assert(np.all(dims == 1))
      variables = np.array([(str(wildcards.POP)),(str(wildcards.POS1)+"-"+str(wildcards.POS2)),(int(wildcards.EPS)/10000),(int(wildcards.N)),(int(wildcards.BLEN))])
      # Stack the array in a clever way
      adaptive_ld_mat, idxs = stack_ragged(full_r2_list)
      np.savez_compressed(output.adaptive_ld_mat,
                          adaptive_ld_mat=adaptive_ld_mat, idx=idxs,
                          chroms=chroms[idx_polymorphic], positions=positions[idx_polymorphic], alt_af = alt_af_filt, variables = variables)
        
rule adaptive_ld_mats:
    input:
        expand('data/performance_tests/adaptive_chr{CHROM}_eps{EPS}_N{N}_blen{BLEN}_ac{AC}_pos{POS1}_{POS2}_pop{POP}.npz', CHROM=22, AC=5, POP=['CEU','CHB','YRI','FIN','ASW','MXL'],POS1=17000000, POS2=20000000, EPS=[10,25,100,1000],N=[25,50],BLEN=[100,250,500])
        
     
rule adaptive_k_single_pop_chrom_v2:
    """
        Generate list containing r2 arrays for each SNP on a chromosome for a population
        Uses version of algorithm without blen parameter
    """
    input:
      vcf = rules.filt_biallelic_AC_1kg.output.vcf,
      popfile = VCF_1KG_DIR + 'integrated_call_samples_v3.20130502.ALL.panel'
    output:
      adaptive_ld_mat = 'data/performance_tests/adaptive_v2_chr{CHROM}_eps{EPS,\d+}_N{N,\d+}_ac{AC,\d+}_pos{POS1,\d+}_{POS2,\d+}_pop{POP}.npz'    
    run:
      # Reading in vcf
      callset = allel.read_vcf(input.vcf, region=(str(wildcards.CHROM))+':'+str(wildcards.POS1)+'-'+str(wildcards.POS2), 
                               fields=['variants/CHROM', 'calldata/GT','samples','variants/POS'])
      chroms = callset['variants/CHROM']
      positions = callset['variants/POS']
      # Generating genotype array
      gt = allel.GenotypeArray(callset['calldata/GT'])
      # Filtering out particular population
      panel = pd.read_csv(input.popfile, sep='\t', usecols=['sample', 'pop', 'super_pop'])
      pop_check = (panel['pop']==wildcards.POP)
      pop_indices = panel[pop_check].index.values
      pop_gt = gt.take(pop_indices, axis=1)
      # Creating summed genotype matrix
      gt_mat = pop_gt.to_n_alt()
      _, nsamp = gt_mat.shape
      # Calculate alt AF
      alt_af = np.sum(gt_mat, axis=1)/(2*nsamp)
      
      # Filter this to only the sites that are polymorphic
      idx_polymorphic = ((alt_af > 0) & (alt_af < 1))
      alt_af_filt = alt_af[idx_polymorphic]
      gt_mat_filt = gt_mat[idx_polymorphic,:]
      nsnps_filt, nsamp_filt = gt_mat_filt.shape
      
      # Empty list for arrays
      full_r2_list = []
      # Appending each array to list and saving
      for i in tqdm(range(nsnps_filt)):
        snp_r2_adaptive = adaptive_ld_mat_snp_v2(gt_mat_filt, i,int(wildcards.EPS)/10000,int(wildcards.N))
        full_r2_list.append(snp_r2_adaptive)
      # Check the dimension of these arrays to make sure they are all 1-d
      #dims = np.array([x.ndim for x in full_r2_list])
      #assert(np.all(dims == 1))
      variables = np.array([(str(wildcards.POP)),(str(wildcards.POS1)+"-"+str(wildcards.POS2)),(int(wildcards.EPS)/10000),(int(wildcards.N))])
      # Stack the array in a clever way
      adaptive_ld_mat, idxs = stack_ragged(full_r2_list)
      np.savez_compressed(output.adaptive_ld_mat,
                          adaptive_ld_mat=adaptive_ld_mat, idx=idxs,
                          chroms=chroms[idx_polymorphic], positions=positions[idx_polymorphic], alt_af = alt_af_filt, variables = variables)
        
poplist = ['CEU','CHB','YRI','FIN','MXL','ASW']
        
rule adaptive_ld_mats_v2:
    input:
        expand('data/performance_tests/adaptive_v2_chr{CHROM}_eps{EPS}_N{N}_ac{AC}_pos{POS1}_{POS2}_pop{POP}.npz', CHROM=22, AC=5, POP=poplist,POS1=48000000, POS2=51000000, EPS=[500],N=[25,50])

eps_list = [50,100,500]
N_list = [25,50]
blen_list = [100,250,500]
chrom = 22
ac = 5
pos1 = 17000000
pos2 = 20000000
pop = 'FIN'
poslist = ['pos17000000_20000000','pos25000000_28000000','pos33000000_36000000','pos41000000_44000000','pos48000000_51000000']
        
rule adaptive_perf_csv:
    """
       Generate a csv file with each row containing performance testing data and relevant 
       variables for the adaptive arrays from a particular region for a given population
    """
    input:
      adaptive = expand('/project2/jnovembre/achyutha11/geo_LD_viz_v2/data/performance_tests/adaptive_chr{CHROM}_eps{EPS}_N{N}_blen{BLEN}_ac{AC}_pos{POS1}_{POS2}_pop{POP}.npz',
                        CHROM=22,EPS=eps_list,N=N_list,BLEN=blen_list,AC=5,POS1=17000000,POS2=20000000,POP='CEU'),
      full = '/project2/jnovembre/achyutha11/geo_LD_viz_v2/data/ld_mats_perf/chr'+str(chrom)+'_ac'+str(ac)+'_full_LD_pos'+str(pos1)+'_'+str(pos2)+'_pop'+str(pop)+'.npz'
    output:
      csv = '/project2/jnovembre/achyutha11/geo_LD_viz_v2/data/performance_tests/adaptive_perf_chr{CHROM}_ac{AC,\d+}_pos{POS1,\d+}_{POS2,\d+}_pop{POP}.csv'
    benchmark:
      "benchmark/{CHROM}_{AC,\d+}_{POS1,\d+}_{POS2,\d+}_{POP}.adaptive_csv.benchmark.txt"
    run:
      with open(output.csv,'w',newline='') as file:
        writer = csv.writer(file)
        writer.writerow(["pop","region","eps_thresh", "n", "blen",'eps_r2','adaptive > eps','true > eps','adaptive_total','true_total','corrcoef'])
      load = np.load(input.full)
      mat = load['ld_mat']
      for i in input.adaptive:
        adaptive_load = adaptive_file_convert(i)
        eps_list = [0.1,0.25,0.5,0.8]
        for j in eps_list:
            with open(output.csv,'a+',newline='') as file:
                writer = csv.writer(file)
                writer.writerow(perf_adaptive(mat,adaptive_load,j))
                
                
rule adaptive_csv_gen:
    input:
        expand('/project2/jnovembre/achyutha11/geo_LD_viz_v2/data/performance_tests/adaptive_perf_chr{CHROM}_ac{AC}_pos{POS1}_{POS2}_pop{POP}.csv', CHROM=22, AC=5, POP='ASW',POS1=48000000, POS2=51000000, EPS=[10,100,1000],N=[25,50],BLEN=[100,250,500])
        
        
rule adaptive_perf_csv_v2:
    """
       Generate a csv file with each row containing performance testing data and relevant 
       variables for the adaptive arrays from a particular region for a given population
    """
    input:
      adaptive = expand('/project2/jnovembre/achyutha11/geo_LD_viz_v2/data/performance_tests/adaptive_v2_chr{CHROM}_eps{EPS}_N{N}_ac{AC}_pos{POS1}_{POS2}_pop{POP}.npz',
                        CHROM=22,EPS=eps_list,N=N_list,AC=5,POS1=17000000,POS2=20000000,POP='FIN'),
      full = '/project2/jnovembre/achyutha11/geo_LD_viz_v2/data/ld_mats_perf/chr'+str(chrom)+'_ac'+str(ac)+'_full_LD_pos'+str(pos1)+'_'+str(pos2)+'_pop'+str(pop)+'.npz'
    output:
      csv = '/project2/jnovembre/achyutha11/geo_LD_viz_v2/data/performance_tests/adaptive_v2_perf_chr{CHROM}_ac{AC,\d+}_pos{POS1,\d+}_{POS2,\d+}_pop{POP}.csv'
    benchmark:
      "benchmark/{CHROM}_{AC,\d+}_{POS1,\d+}_{POS2,\d+}_{POP}.adaptive_csv_v2.benchmark.txt"
    run:
      with open(output.csv,'w',newline='') as file:
        writer = csv.writer(file)
        writer.writerow(["pop","region","eps_thresh", "n",'eps_r2','adaptive > eps','true > eps','adaptive_total','true_total','corrcoef'])
      load = np.load(input.full)
      mat = load['ld_mat']
      for i in input.adaptive:
        adaptive_load = adaptive_file_convert(i)
        eps_list = [0.1,0.25,0.5,0.8]
        for j in eps_list:
            with open(output.csv,'a+',newline='') as file:
                writer = csv.writer(file)
                writer.writerow(perf_adaptive_v2(mat,adaptive_load,j))
                
                
rule adaptive_csv_gen_v2:
    input:
        expand('/project2/jnovembre/achyutha11/geo_LD_viz_v2/data/performance_tests/adaptive_v2_perf_chr{CHROM}_ac{AC}_pos{POS1}_{POS2}_pop{POP}.csv', CHROM=22, AC=5, POP='FIN',POS1=17000000, POS2=20000000, EPS=[50,100,500],N=[25,50])


rule adaptive_perf_csv_emp:
    """
       Generate a csv file with each row containing performance testing data and relevant 
       variables for the adaptive arrays from a particular region for a given population
    """
    input:
      adaptive = expand('/project2/jnovembre/achyutha11/geo_LD_viz_v2/data/performance_tests/adaptive_v2_chr{CHROM}_eps{EPS}_N{N}_ac{AC}_pos{POS1}_{POS2}_pop{POP}.npz',
                        CHROM=22,EPS=500,N=[130,260],AC=5,POS1=48000000,POS2=51000000,POP='CEU'),
      full = '/project2/jnovembre/achyutha11/geo_LD_viz_v2/data/ld_mats_perf/chr'+str(chrom)+'_ac'+str(ac)+'_full_LD_pos'+str(pos1)+'_'+str(pos2)+'_pop'+str(pop)+'.npz'
    output:
      csv = '/project2/jnovembre/achyutha11/geo_LD_viz_v2/data/performance_tests/adaptive_emp_perf_chr{CHROM}_ac{AC,\d+}_pos{POS1,\d+}_{POS2,\d+}_pop{POP}.csv'
    benchmark:
      "benchmark/{CHROM}_{AC,\d+}_{POS1,\d+}_{POS2,\d+}_{POP}.adaptive_emp_csv.benchmark.txt"
    run:
      with open(output.csv,'w',newline='') as file:
        writer = csv.writer(file)
        writer.writerow(["pop","region","eps_thresh", "n",'eps_r2','adaptive > eps','true > eps','adaptive_total','true_total','corrcoef'])
      load = np.load(input.full)
      mat = load['ld_mat']
      for i in input.adaptive:
        adaptive_load = adaptive_file_convert(i)
        eps_list = [0.1,0.25,0.5,0.8]
        for j in eps_list:
            with open(output.csv,'a+',newline='') as file:
                writer = csv.writer(file)
                writer.writerow(perf_adaptive_v2(mat,adaptive_load,j))
                
                
rule adaptive_csv_gen_emp:
    input:
        expand('/project2/jnovembre/achyutha11/geo_LD_viz_v2/data/performance_tests/adaptive_emp_perf_chr{CHROM}_ac{AC}_pos{POS1}_{POS2}_pop{POP}.csv', CHROM=22, AC=5, POP='CEU',POS1=48000000, POS2=51000000, EPS=[500],N=[130,260])
        
rule merge_regional_csv:
    """
       Generate a meta csv file containing all population data for a particular region of a chromosome 
    """
    input:
      csv_list = expand('/project2/jnovembre/achyutha11/geo_LD_viz_v2/data/performance_tests/adaptive_perf_chr{CHROM}_ac{AC}_{pos}_pop{POP}.csv',
                        CHROM=22,AC=5,POP=poplist, pos=poslist),
    output:
      meta_csv = '/project2/jnovembre/achyutha11/geo_LD_viz_v2/data/performance_tests/adaptive_perf_chr{CHROM}_ac{AC,\d+}_meta.csv'
    run:
      merge_csv = pd.concat([pd.read_csv(i) for i in input.csv_list])
      merge_csv.to_csv(output.meta_csv)
      
rule meta_csv_gen:
    input:
        expand('/project2/jnovembre/achyutha11/geo_LD_viz_v2/data/performance_tests/adaptive_perf_chr{CHROM}_ac{AC}_meta.csv', CHROM=22, AC=5)
        
rule merge_regional_csv_v2:
    """
       Generate a meta csv file containing all population data for a particular region of a chromosome 
    """
    input:
      csv_list = expand('/project2/jnovembre/achyutha11/geo_LD_viz_v2/data/performance_tests/adaptive_v2_perf_chr{CHROM}_ac{AC}_{pos}_pop{POP}.csv',
                        CHROM=22,AC=5,POP=poplist, pos=poslist),
    output:
      meta_csv = '/project2/jnovembre/achyutha11/geo_LD_viz_v2/data/performance_tests/adaptive_v2_perf_chr{CHROM}_ac{AC,\d+}_meta.csv'
    run:
      merge_csv = pd.concat([pd.read_csv(i) for i in input.csv_list])
      merge_csv.to_csv(output.meta_csv)
      
rule meta_csv_gen_v2:
    input:
        expand('/project2/jnovembre/achyutha11/geo_LD_viz_v2/data/performance_tests/adaptive_v2_perf_chr{CHROM}_ac{AC}_meta.csv', CHROM=22, AC=5)
        
        
rule snp_dist_csv:
    """
       Generate a meta csv file containing avg SNP distance to go below a certain epsilon threshold
    """
    input:
      csv_list = expand('/project2/jnovembre/achyutha11/geo_LD_viz_v2/data/ld_mats_perf/chr{CHROM}_ac{AC}_full_LD_{pos}_pop{POP}.npz',
                        CHROM=22,AC=5,POP=poplist, pos=poslist),
    output:
      meta_csv = '/project2/jnovembre/achyutha11/geo_LD_viz_v2/data/performance_tests/adaptive_SNP_dist_chr{CHROM}_ac{AC,\d+}_meta.csv'
    run:
      with open(output.meta_csv,'w',newline='') as file:
        writer = csv.writer(file)
        writer.writerow(['pop','region','eps','avg_dist'])
      for i in input.csv_list:
        eps_list = [0.1,0.01,0.001]
        for j in eps_list:
            with open(output.meta_csv,'a+',newline='') as file:
                writer = csv.writer(file)
                writer.writerow(avg_SNP_dist(i,j))

      
rule snp_dist_csv_gen:
    input:
        expand('/project2/jnovembre/achyutha11/geo_LD_viz_v2/data/performance_tests/adaptive_SNP_dist_chr{CHROM}_ac{AC}_meta.csv', CHROM=22, AC=5)
        
   
rule mean_r2_values:
    """
        Generate list containing mean r2 values at each increment in SNP distance for a particular chromosome for a particular population
    """
    input:
      vcf = rules.filt_biallelic_AC_1kg.output.vcf,
      popfile = VCF_1KG_DIR + 'integrated_call_samples_v3.20130502.ALL.panel'
    output:
      mean_r2 = '/project2/jnovembre/achyutha11/geo_LD_viz_v2/data/performance_tests/mean_r2_x{X,\d+}_eps{EPS,\d+}_chr{CHROM}_ac{AC,\d+}_pop{POP}.npz' 
    benchmark:
      "benchmark/x{X,\d+}_eps{EPS,\d+}_{CHROM}_{AC,\d+}_{POP}.mean_r2.benchmark.txt"
    run:
      # Reading in vcf
      callset = allel.read_vcf(input.vcf, fields=['calldata/GT'])
      # Generating genotype array
      gt = allel.GenotypeArray(callset['calldata/GT'])
      # Filtering out particular population
      panel = pd.read_csv(input.popfile, sep='\t', usecols=['sample', 'pop', 'super_pop'])
      pop_check = (panel['pop']==wildcards.POP)
      pop_indices = panel[pop_check].index.values
      pop_gt = gt.take(pop_indices, axis=1)
      # Creating summed genotype matrix
      gt_mat = pop_gt.to_n_alt()
      _, nsamp = gt_mat.shape
      # Calculate alt AF
      alt_af = np.sum(gt_mat, axis=1)/(2*nsamp)
      
      # Filter this to only the sites that are polymorphic
      idx_polymorphic = ((alt_af > 0) & (alt_af < 1))
      alt_af_filt = alt_af[idx_polymorphic]
      gt_mat_filt = gt_mat[idx_polymorphic,:]
      nsnps_filt, nsamp_filt = gt_mat_filt.shape
      
      r2_list = n_finder(gt_mat_filt, int(wildcards.X), (int(wildcards.EPS)/10000))[1]
      r2_array = np.array(r2_list)
      np.savez_compressed(output.mean_r2, r2_array = r2_array)
        
rule mean_r2_values_gen:
    input:
        expand('/project2/jnovembre/achyutha11/geo_LD_viz_v2/data/performance_tests/mean_r2_x{X}_eps{EPS}_chr{CHROM}_ac{AC}_pop{POP}.npz', CHROM=22, AC=5, POP=poplist,EPS=[1000,500],X=10000)
        
        
rule mean_r2_values_v2:
    """
        Generate list containing mean r2 values at each increment in SNP distance for a particular chromosome for a particular population
        Uses second n-finder function that takes different sample of SNPs in each iteration
    """
    input:
      vcf = rules.filt_biallelic_AC_1kg.output.vcf,
      popfile = VCF_1KG_DIR + 'integrated_call_samples_v3.20130502.ALL.panel'
    output:
      mean_r2 = '/project2/jnovembre/achyutha11/geo_LD_viz_v2/data/performance_tests/mean_r2_v2_x{X,\d+}_eps{EPS,\d+}_chr{CHROM}_ac{AC,\d+}_pop{POP}.npz' 
    benchmark:
      "benchmark/x{X,\d+}_eps{EPS,\d+}_{CHROM}_{AC,\d+}_{POP}.mean_r2_v2.benchmark.txt"
    run:
      # Reading in vcf
      callset = allel.read_vcf(input.vcf, fields=['calldata/GT'])
      # Generating genotype array
      gt = allel.GenotypeArray(callset['calldata/GT'])
      # Filtering out particular population
      panel = pd.read_csv(input.popfile, sep='\t', usecols=['sample', 'pop', 'super_pop'])
      pop_check = (panel['pop']==wildcards.POP)
      pop_indices = panel[pop_check].index.values
      pop_gt = gt.take(pop_indices, axis=1)
      # Creating summed genotype matrix
      gt_mat = pop_gt.to_n_alt()
      _, nsamp = gt_mat.shape
      # Calculate alt AF
      alt_af = np.sum(gt_mat, axis=1)/(2*nsamp)
      
      # Filter this to only the sites that are polymorphic
      idx_polymorphic = ((alt_af > 0) & (alt_af < 1))
      alt_af_filt = alt_af[idx_polymorphic]
      gt_mat_filt = gt_mat[idx_polymorphic,:]
      nsnps_filt, nsamp_filt = gt_mat_filt.shape
      
      r2_list = n_finder_v2(gt_mat_filt, int(wildcards.X), (int(wildcards.EPS)/10000))[1]
      r2_array = np.array(r2_list)
      np.savez_compressed(output.mean_r2, r2_array = r2_array)
        
rule mean_r2_values_gen_v2:
    input:
        expand('/project2/jnovembre/achyutha11/geo_LD_viz_v2/data/performance_tests/mean_r2_v2_x{X}_eps{EPS}_chr{CHROM}_ac{AC}_pop{POP}.npz', CHROM=22, AC=5, POP=poplist,EPS=[1000,500],X=10000)
